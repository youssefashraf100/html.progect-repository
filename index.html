<html>
    <body>
        <h1>Artificial intelligence</h1>

        <h2><links: ></h2>
        <u1>
            <li><a href="file:///C:/Users/lenovo/3D%20Objects/1.html" target="_blank">Philosophy of artificial intelligence</a></li>
            <li><a href="file:///C:/Users/lenovo/3D%20Objects/2.html" target="_blank">Artificial Intelligence (AI)</a></li>
            <li>,<a href="file:///C:/Users/lenovo/3D%20Objects/text.html/3.html" target="_blank">Physical symbol system</a></li>
            <li><a href="file:///C:/Users/lenovo/3D%20Objects/4.html" target="_blank">Top 10 Benefits of Artificial Intelligence (AI)</a></li>
        </u1>

<h2>Natural-language generation</h2>
Natural-language generation (NLG) is a software process that produces natural language output. While it is widely agreed that the output of any NLG process is text, there is some disagreement on whether the inputs of an NLG system need to be non-linguistic.[1] Common applications of NLG methods include the production of various reports, for example weather [2] and patient reports;[3] image captions;[4] and chatbots.

Automated NLG can be compared to the process humans use when they turn ideas into writing or speech. Psycholinguists prefer the term language production for this process, which can also be described in mathematical terms, or modeled in a computer for psychological research. NLG systems can also be compared to translators of artificial computer languages, such as decompilers or transpilers, which also produce human-readable code generated from an intermediate representation. Human languages tend to be considerably more complex and allow for much more ambiguity and variety of expression than programming languages, which makes NLG more challenging.

NLG may be viewed as complementary to natural-language understanding (NLU): whereas in natural-language understanding, the system needs to disambiguate the input sentence to produce the machine representation language, in NLG the system needs to make decisions about how to put a representation into words. The practical considerations in building NLU vs. NLG systems are not symmetrical. NLU needs to deal with ambiguous or erroneous user input, whereas the ideas the system wants to express through NLG are generally known precisely. NLG needs to choose a specific, self-consistent textual representation from many potential representations, whereas NLU generally tries to produce a single, normalized representation of the idea expressed.[5]

NLG has existed since ELIZA was developed in the mid 1960s, but the methods were first used commercially in the 1990s.[6] NLG techniques range from simple template-based systems like a mail merge that generates form letters, to systems that have a complex understanding of human grammar. NLG can also be accomplished by training a statistical model using machine learning, typically on a large corpus of human-written texts.
<img src="https://tse1.mm.bing.net/th?id=OIP.JjkNrMFx5jBKb0eDteXCZgHaDm&pid=Api&P=0&w=362&h=177"  width="500". hspace="500"/>
<h2>Knowledge representation and reasoning</h2>
Knowledge representation and reasoning (KRÂ², KR&R) is the field of artificial intelligence (AI) dedicated to representing information about the world in a form that a computer system can utilize to solve complex tasks such as diagnosing a medical condition or having a dialog in a natural language. Knowledge representation incorporates findings from psychology[1] about how humans solve problems and represent knowledge in order to design formalisms that ill make complex systems easier to design and build. Knowledge representation and reasoning also incorporates findings from logic to automate various kinds of reasoning, such as the application of rules or the relations of sets and subsets.
Examples of knowledge representation formalisms include semantic nets, systems architecture, frames, rules, and ontologies. Examples of automated reasoning engines include inference engines, theorem provers.
<img src="https://tse2.mm.bing.net/th?id=OIP.uuD1m5LUmtNzzKWEHR5VEgHaEL&pid=Api&P=0&w=283&h=160" width="500" hspace="500"/>
<h2>Robotics</h2>
Robotics is an interdisciplinary field that integrates computer science and engineering.[1] Robotics involves design, construction, operation, and use of robots. The goal of robotics is to design machines that can help and assist humans. Robotics integrates fields of mechanical engineering, electrical engineering, information engineering, mechatronics, electronics, bioengineering, computer engineering, control engineering, software engineering, mathematics, among others.

Robotics develops machines that can substitute for humans and replicate human actions. Robots can be used in many situations and for many purposes, but today many are used in dangerous environments (including inspection of radioactive materials, bomb detection and deactivation), manufacturing processes, or where humans cannot survive (e.g. in space, underwater, in high heat, and clean up and containment of hazardous materials and radiation). Robots can take on any form but some are made to resemble humans in appearance. This is said to help in the acceptance of a robot in certain replicative behaviors usually performed by people. Such robots attempt to replicate walking, lifting, speech, cognition, or any other human activity. Many of today's robots are inspired by nature, contributing to the field of bio-inspired robotics.

Certain robots require user input to operate while other robots function autonomously. The concept of creating robots that can operate autonomously dates back to classical times, but research into the functionality and potential uses of robots did not grow substantially until the 20th century. Throughout history, it has been frequently assumed by various scholars, inventors, engineers, and technicians that robots will one day be able to mimic human behavior and manage tasks in a human-like fashion. Today, robotics is a rapidly growing field, as technological advances continue; researching, designing, and building new robots serve various practical purposes, whether domestically, commercially, or militarily. Many robots are built to do jobs that are hazardous to people, such as defusing bombs, finding survivors in unstable ruins, and exploring mines and shipwrecks. Robotics is also used in STEM (science, technology, engineering, and mathematics) as a teaching aid
<img src="https://www.analyticsinsight.net/wp-content/uploads/2020/04/Robotics-1.jpg" width="500" hspace="500"/>
<h2>Affective computing</h2>
Affective computing is the study and development of systems and devices that can recognize, interpret, process, and simulate human affects. It is an interdisciplinary field spanning computer science, psychology, and cognitive science.[1] While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion,[2] the more modern branch of computer science originated with Rosalind Picard's 1995 paper[3] on affective computing and her book Affective Computing[4] published by MIT Press.[5][6] One of the motivations for the research is the ability to give machines emotional intelligence, including to simulate empathy. The machine should interpret the emotional state of humans and adapt its behavior to them, giving an appropriate response to those emotions.

<img src="https://cdn.nanalyze.com/uploads/2016/04/Affective-Computing-Teaser.jpg" width="500" hspace="500"/>
</body>
<h3>by youssef ashraf abdelmoez </h3>
    <h3>group 8</h3>
    <h3>section 47</h3>
    <h3> BN 13</h3>
</html>